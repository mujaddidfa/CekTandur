{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3333fa25-6e58-41e9-9d95-94a5e7ec8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a815eb71-f670-47b1-aad1-6694a8bcb742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'ClearDataset/tandur_data/train'\n",
    "val_dir = 'ClearDataset/tandur_data/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62bd6d98-56e3-40a8-8f4b-d205714abeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalisasi gambar\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13f1ceb8-35a6-41ed-b1af-f3dab06a4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bab3d507-a622-4711-8cf1-82d9f4190c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46358 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  # Ukuran input untuk MobileNet\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # untuk klasifikasi multi-kelas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81dbf518-d205-43a5-acb0-89c5650e9f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11588 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81cc40bf-afe2-4ffb-9f0c-9f71e4b091de",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Menambahkan lapisan-lapisan baru di atas base model\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)  # Global Average Pooling layer\n",
    "x = layers.Dense(1024, activation='relu')(x)  # Lapisan dense\n",
    "x = layers.Dropout(0.5)(x)  # Dropout untuk regularisasi\n",
    "predictions = layers.Dense(train_generator.num_classes, activation='softmax')(x)  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27c4bd08-b0c2-4dc9-a33e-6fbd6badfbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad7d62da-1dc6-4c66-ae68-4e140b1f9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e543d12c-2e38-497c-b294-3a5287b87bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b596f39-d11c-4140-9c7a-2b6c2defd73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wan/anaconda3/envs/tf2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 321ms/step - accuracy: 0.7157 - loss: 0.9255 - val_accuracy: 0.8795 - val_loss: 0.3480\n",
      "Epoch 2/10\n",
      "\u001b[1m   1/1448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 0.5315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wan/anaconda3/envs/tf2/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8438 - loss: 0.5315 - val_accuracy: 0.5000 - val_loss: 2.4285\n",
      "Epoch 3/10\n",
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 205ms/step - accuracy: 0.8557 - loss: 0.4270 - val_accuracy: 0.8998 - val_loss: 0.2899\n",
      "Epoch 4/10\n",
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6us/step - accuracy: 0.9688 - loss: 0.1130 - val_accuracy: 0.7500 - val_loss: 0.2358\n",
      "Epoch 5/10\n",
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 210ms/step - accuracy: 0.8706 - loss: 0.3859 - val_accuracy: 0.9210 - val_loss: 0.2361\n",
      "Epoch 6/10\n",
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7us/step - accuracy: 0.8438 - loss: 0.3403 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:26:14.649036: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3140085843291211997\n",
      "2024-12-04 01:26:14.649085: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11721142309957638537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 210ms/step - accuracy: 0.8754 - loss: 0.3679 - val_accuracy: 0.9062 - val_loss: 0.2661\n",
      "Epoch 8/10\n",
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16us/step - accuracy: 0.9375 - loss: 0.1895 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:31:18.741806: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11721142309957638537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 241ms/step - accuracy: 0.8824 - loss: 0.3482 - val_accuracy: 0.9224 - val_loss: 0.2284\n",
      "Epoch 10/10\n",
      "\u001b[1m1448/1448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7us/step - accuracy: 0.9375 - loss: 0.2172 - val_accuracy: 0.7500 - val_loss: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:37:07.914855: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 3140085843291211997\n",
      "2024-12-04 01:37:07.914902: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 11721142309957638537\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9afdf101-fc35-4efc-b122-3121737f95e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.9213 - loss: 0.2328\n",
      "Loss: 0.22927053272724152, Accuracy: 0.9225923418998718\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(val_generator)\n",
    "print(f\"Loss: {score[0]}, Accuracy: {score[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcdecc47-c62a-4196-bc74-186f61306132",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mobilenet_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5aa8f0c2-d8d2-40e5-b8a8-97bca81332fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('mobilenet_model.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b1d083f-292f-4386-8080-fa2314662d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b53cd-ecac-40c8-92bf-b27a00f8289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 01:46:59.335664: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11219', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 640/1448\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 197ms/step - accuracy: 0.6687 - loss: 1.1898"
     ]
    }
   ],
   "source": [
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[early_stopping, lr_scheduler, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "805842e9-aee4-4a8f-a0b0-4bb0e2a0291d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3641c4-8248-44b7-90f8-59e938d9ea78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
